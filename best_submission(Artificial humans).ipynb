{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53383bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train/test CSVs...\n",
      "Numeric features (25): ['Unique ID', 'Rider_ID', 'Len_Circuit_inkm', 'Laps', 'Start_Position', 'Formula_Avg_Speed_kmh', 'Humidity_%', 'Champ_Points', 'Champ_Position', 'race_year', 'seq', 'position', 'points', 'Corners_in_Lap', 'Tire_Degradation_Factor_per_Lap', 'Pit_Stop_Duration_Seconds', 'Ambient_Temperature_Celsius', 'Track_Temperature_Celsius', 'air', 'ground', 'starts', 'finishes', 'with_points', 'podiums', 'wins']\n",
      "One-hot categorical (7): ['Formula_category_x', 'Formula_Track_Condition', 'Tire_Compound', 'Penalty', 'Session', 'weather', 'track']\n",
      "Freq categorical (2): ['Formula_shortname', 'circuit_name']\n",
      "\n",
      "========================================\n",
      "Running model: rf\n",
      "========================================\n",
      "\n",
      "-- Fold 1/5 --\n",
      "Fold 1 RMSE: 0.1852\n",
      "\n",
      "-- Fold 2/5 --\n",
      "Fold 2 RMSE: 0.1580\n",
      "\n",
      "-- Fold 3/5 --\n",
      "Fold 3 RMSE: 0.1770\n",
      "\n",
      "-- Fold 4/5 --\n",
      "Fold 4 RMSE: 0.2090\n",
      "\n",
      "-- Fold 5/5 --\n",
      "Fold 5 RMSE: 0.1727\n",
      "\n",
      "RF CV mean RMSE: 0.1804 ± 0.0168\n",
      "RF OOF RMSE: 0.1811\n",
      "\n",
      "Training final rf model on full data...\n",
      "Saved rf_final_model.joblib and rf_preprocessor.joblib\n",
      "Finished model: rf\n",
      "\n",
      "\n",
      "========================================\n",
      "Running model: et\n",
      "========================================\n",
      "\n",
      "-- Fold 1/5 --\n",
      "Fold 1 RMSE: 0.0811\n",
      "\n",
      "-- Fold 2/5 --\n",
      "Fold 2 RMSE: 0.0461\n",
      "\n",
      "-- Fold 3/5 --\n",
      "Fold 3 RMSE: 0.0735\n",
      "\n",
      "-- Fold 4/5 --\n",
      "Fold 4 RMSE: 0.0995\n",
      "\n",
      "-- Fold 5/5 --\n",
      "Fold 5 RMSE: 0.0674\n",
      "\n",
      "ET CV mean RMSE: 0.0735 ± 0.0174\n",
      "ET OOF RMSE: 0.0755\n",
      "\n",
      "Training final et model on full data...\n",
      "Saved et_final_model.joblib and et_preprocessor.joblib\n",
      "Finished model: et\n",
      "\n",
      "✅ All done.\n"
     ]
    }
   ],
   "source": [
    "##best submission\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "\n",
    "\n",
    "\n",
    "class ValueCountMapper:\n",
    "    def _init_(self, normalize=True, suffix=\"_freq\"):\n",
    "        self.normalize = normalize\n",
    "        self.suffix = suffix\n",
    "        self.count_maps_ = {}\n",
    "        self.columns_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_df = pd.DataFrame(X)\n",
    "        self.columns_ = [str(c) for c in X_df.columns.tolist()]\n",
    "        self.count_maps_ = {} \n",
    "        \n",
    "        for idx, orig_col in enumerate(X_df.columns):\n",
    "            col_str = self.columns_[idx]\n",
    "            \n",
    "            vc = X_df[orig_col].value_counts(\n",
    "                normalize=self.normalize, \n",
    "                dropna=False\n",
    "            )\n",
    "            self.count_maps_[col_str] = vc.to_dict()\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_df = pd.DataFrame(X, columns=self.columns_)\n",
    "        out = pd.DataFrame(index=X_df.index)\n",
    "        \n",
    "        for col in self.columns_:\n",
    "            mapping = self.count_maps_.get(col, {})\n",
    "            \n",
    "            new_col_name = str(col) + self.suffix\n",
    "            out[new_col_name] = X_df[col].map(mapping).fillna(0.0).astype(float)\n",
    "            \n",
    "        return out.values\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        cols = input_features if input_features is not None else self.columns_\n",
    "        return [str(c) + self.suffix for c in cols]\n",
    "\n",
    "\n",
    "def make_ohe(sparse_output=False):\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=sparse_output)\n",
    "    except TypeError:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse=not sparse_output)\n",
    "\n",
    "\n",
    "train_path = r\"train.csv\"\n",
    "test_path  = r\"test.csv\"\n",
    "\n",
    "ID_COL = \"id\"\n",
    "TARGET = \"Lap_Time_Seconds\"\n",
    "\n",
    "cat_onehot = ['Formula_category_x', 'Formula_Track_Condition', 'Tire_Compound',\n",
    "              'Penalty', 'Session', 'weather', 'track']\n",
    "cat_freq = ['Formula_shortname', 'circuit_name']\n",
    "\n",
    "numeric_cols_all = ['id', 'Unique ID', 'Rider_ID', 'Len_Circuit_inkm', 'Laps',\n",
    "                    'Start_Position', 'Formula_Avg_Speed_kmh', 'Humidity_%',\n",
    "                    'Champ_Points', 'Champ_Position', 'race_year', 'seq', 'position',\n",
    "                    'points', 'Corners_in_Lap', 'Tire_Degradation_Factor_per_Lap',\n",
    "                    'Pit_Stop_Duration_Seconds', 'Ambient_Temperature_Celsius',\n",
    "                    'Track_Temperature_Celsius', 'air', 'ground', 'starts',\n",
    "                    'finishes', 'with_points', 'podiums', 'wins', 'Lap_Time_Seconds']\n",
    "\n",
    "\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "rf_params = dict(\n",
    "    n_estimators=200, max_depth=None, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "et_params = dict(\n",
    "    n_estimators=300, max_depth=None, random_state=42, n_jobs=-1, bootstrap=False\n",
    ")\n",
    "\n",
    "USE_SPARSE_OHE = False\n",
    "\n",
    "print(\"Loading train/test CSVs...\")\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "if ID_COL not in train_df.columns or TARGET not in train_df.columns:\n",
    "    raise ValueError(\"train.csv must contain 'id' and 'Lap_Time_Seconds' columns.\")\n",
    "if ID_COL not in test_df.columns:\n",
    "    raise ValueError(\"test.csv must contain 'id' column.\")\n",
    "\n",
    "cat_onehot = [c for c in cat_onehot if c in train_df.columns]\n",
    "cat_freq = [c for c in cat_freq if c in train_df.columns]\n",
    "numeric_features = [c for c in numeric_cols_all if c in train_df.columns and c not in (ID_COL, TARGET)]\n",
    "\n",
    "print(f\"Numeric features ({len(numeric_features)}): {numeric_features}\")\n",
    "print(f\"One-hot categorical ({len(cat_onehot)}): {cat_onehot}\")\n",
    "print(f\"Freq categorical ({len(cat_freq)}): {cat_freq}\")\n",
    "\n",
    "\n",
    "if 'Penalty' in train_df.columns:\n",
    "    train_df['Penalty'] = train_df['Penalty'].fillna('NoPenalty')\n",
    "if 'Penalty' in test_df.columns:\n",
    "    test_df['Penalty'] = test_df['Penalty'].fillna('NoPenalty')\n",
    "\n",
    "X_full = train_df.drop(columns=[TARGET])\n",
    "y_full = train_df[TARGET].values\n",
    "\n",
    "\n",
    "def build_preprocessor(onehot_cols, freq_cols, numeric_cols, use_sparse_ohe=USE_SPARSE_OHE):\n",
    "    numeric_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    onehot_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Missing\")),\n",
    "        (\"ohe\", make_ohe(sparse_output=use_sparse_ohe))\n",
    "    ])\n",
    "    freq_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Missing\")),\n",
    "        (\"mapper\", ValueCountMapper(normalize=True, suffix=\"_freq\"))\n",
    "    ])\n",
    "\n",
    "    transformers = []\n",
    "    if onehot_cols:\n",
    "        transformers.append((\"onehot\", onehot_transformer, onehot_cols))\n",
    "    if freq_cols:\n",
    "        transformers.append((\"freq_map\", freq_transformer, freq_cols))\n",
    "    if numeric_cols:\n",
    "        transformers.append((\"num\", numeric_transformer, numeric_cols))\n",
    "\n",
    "    return ColumnTransformer(\n",
    "        transformers=transformers, \n",
    "        remainder=\"drop\", \n",
    "        verbose_feature_names_out=False \n",
    "    )\n",
    "\n",
    "\n",
    "models = [\n",
    "    (\"rf\", RandomForestRegressor(**rf_params)),\n",
    "    (\"et\", ExtraTreesRegressor(**et_params))\n",
    "]\n",
    "\n",
    "for model_name, model_obj in models:\n",
    "    print(\"\\n\" + \"=\" * 40)\n",
    "    print(f\"Running model: {model_name}\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    test_preds_cv = np.zeros(len(test_df))\n",
    "    oof_preds = np.zeros(len(train_df))\n",
    "    fold_rmse = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_full, y_full), 1):\n",
    "        print(f\"\\n-- Fold {fold}/{n_splits} --\")\n",
    "        X_tr, X_va = X_full.iloc[train_idx], X_full.iloc[val_idx]\n",
    "        y_tr, y_va = y_full[train_idx], y_full[val_idx]\n",
    "\n",
    "        pre = build_preprocessor(cat_onehot, cat_freq, numeric_features)\n",
    "        pre.fit(X_tr)\n",
    "\n",
    "        X_tr_t = pre.transform(X_tr)\n",
    "        X_va_t = pre.transform(X_va)\n",
    "        X_test_t = pre.transform(test_df)\n",
    "\n",
    "        feat_names = pre.get_feature_names_out()\n",
    "\n",
    "        X_tr_df = pd.DataFrame(X_tr_t, columns=feat_names)\n",
    "        X_va_df = pd.DataFrame(X_va_t, columns=feat_names)\n",
    "        X_test_df = pd.DataFrame(X_test_t, columns=feat_names)\n",
    "\n",
    "        model = RandomForestRegressor(*rf_params) if model_name == \"rf\" else ExtraTreesRegressor(*et_params)\n",
    "        model.fit(X_tr_df, y_tr)\n",
    "\n",
    "        pred_val = model.predict(X_va_df)\n",
    "        oof_preds[val_idx] = pred_val\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(y_va, pred_val))\n",
    "        fold_rmse.append(rmse)\n",
    "        print(f\"Fold {fold} RMSE: {rmse:.4f}\")\n",
    "\n",
    "        test_preds_cv += model.predict(X_test_df) / n_splits\n",
    "\n",
    "    mean_rmse = np.mean(fold_rmse)\n",
    "    std_rmse = np.std(fold_rmse)\n",
    "    overall_oof = np.sqrt(mean_squared_error(y_full, oof_preds))\n",
    "\n",
    "    print(f\"\\n{model_name.upper()} CV mean RMSE: {mean_rmse:.4f} ± {std_rmse:.4f}\")\n",
    "    print(f\"{model_name.upper()} OOF RMSE: {overall_oof:.4f}\")\n",
    "\n",
    "    print(f\"\\nTraining final {model_name} model on full data...\")\n",
    "    pre_full = build_preprocessor(cat_onehot, cat_freq, numeric_features)\n",
    "    pre_full.fit(X_full)\n",
    "    X_full_t = pre_full.transform(X_full)\n",
    "    X_test_t = pre_full.transform(test_df)\n",
    "    \n",
    "    feat_names_full = pre_full.get_feature_names_out()\n",
    "    \n",
    "    X_full_df = pd.DataFrame(X_full_t, columns=feat_names_full)\n",
    "    X_test_df = pd.DataFrame(X_test_t, columns=feat_names_full)\n",
    "\n",
    "    final_model = RandomForestRegressor(*rf_params) if model_name == \"rf\" else ExtraTreesRegressor(*et_params)\n",
    "    final_model.fit(X_full_df, y_full)\n",
    "\n",
    "    joblib.dump(final_model, f\"{model_name}_final_model.joblib\")\n",
    "    joblib.dump(pre_full, f\"{model_name}_preprocessor.joblib\")\n",
    "    print(f\"Saved {model_name}_final_model.joblib and {model_name}_preprocessor.joblib\")\n",
    "\n",
    "    test_pred_final = final_model.predict(X_test_df)\n",
    "\n",
    "    out_cv_avg = pd.DataFrame({ID_COL: test_df[ID_COL], TARGET: test_preds_cv})\n",
    "    out_cv_avg.to_csv(f\"output_cv_avg_{model_name}.csv\", index=False)\n",
    "\n",
    "    out_final = pd.DataFrame({ID_COL: test_df[ID_COL], TARGET: test_pred_final})\n",
    "    if model_name == \"et\":\n",
    "        out_final.to_csv(\"outputET.csv\", index=False)\n",
    "    else:\n",
    "        out_final.to_csv(f\"output_{model_name}.csv\", index=False)\n",
    "\n",
    "    print(f\"Finished model: {model_name}\\n\")\n",
    "\n",
    "print(\"All done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12c004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 best submission\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "class FrequencyEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, normalize=True):\n",
    "        self.normalize = normalize\n",
    "        self.freq_maps_ = {}\n",
    "        self.columns_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_df = pd.DataFrame(X)\n",
    "        self.columns_ = [str(c) for c in X_df.columns.tolist()]\n",
    "        for idx, orig_col in enumerate(X_df.columns):\n",
    "            col_str = self.columns_[idx]\n",
    "            vc = X_df[orig_col].value_counts(normalize=self.normalize, dropna=False)\n",
    "            self.freq_maps_[col_str] = vc.to_dict()\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        X_df = pd.DataFrame(X, columns=self.columns_)\n",
    "        out = pd.DataFrame(index=X_df.index)\n",
    "        for col in self.columns_:\n",
    "            mapping = self.freq_maps_.get(col, {})\n",
    "            out[col + \"_freq\"] = X_df[col].map(mapping).fillna(0.0).astype(float)\n",
    "        return out.values\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        cols = input_features if input_features is not None else self.columns_\n",
    "        return [str(c) + \"_freq\" for c in cols]\n",
    "\n",
    "\n",
    "def make_ohe(sparse_output=False):\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=sparse_output)\n",
    "    except TypeError:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse=not sparse_output)\n",
    "\n",
    "\n",
    "train_path = r\"train.csv\"\n",
    "test_path  = r\"test.csv\"\n",
    "\n",
    "ID_COL = \"id\"\n",
    "TARGET = \"Lap_Time_Seconds\"\n",
    "\n",
    "\n",
    "cat_onehot = ['Formula_category_x', 'Formula_Track_Condition',\n",
    "              'Tire_Compound', 'Penalty', 'Session', 'weather', 'track']\n",
    "cat_freq = ['Formula_shortname', 'circuit_name']\n",
    "\n",
    "numeric_cols_all = ['id', 'Unique ID', 'Rider_ID', 'Len_Circuit_inkm', 'Laps',\n",
    "                    'Start_Position', 'Formula_Avg_Speed_kmh', 'Humidity_%',\n",
    "                    'Champ_Points', 'Champ_Position', 'race_year', 'seq', 'position',\n",
    "                    'points', 'Corners_in_Lap', 'Tire_Degradation_Factor_per_Lap',\n",
    "                    'Pit_Stop_Duration_Seconds', 'Ambient_Temperature_Celsius',\n",
    "                    'Track_Temperature_Celsius', 'air', 'ground', 'starts',\n",
    "                    'finishes', 'with_points', 'podiums', 'wins', 'Lap_Time_Seconds']\n",
    "\n",
    "n_splits = 5  \n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "xgb_params = dict(\n",
    "    n_estimators=200, max_depth=7, learning_rate=0.05,\n",
    "    subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1, verbosity=0\n",
    ")\n",
    "\n",
    "rf_params  = dict(\n",
    "    n_estimators=200, max_depth=None, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "et_params = dict(\n",
    "    n_estimators=600, max_depth=None, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "USE_SPARSE_OHE = False\n",
    "\n",
    "\n",
    "print(\"Loading train/test CSVs...\")\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df  = pd.read_csv(test_path)\n",
    "\n",
    "if ID_COL not in train_df.columns or TARGET not in train_df.columns:\n",
    "    raise ValueError(\"train.csv must contain 'id' and 'Lap_Time_Seconds' columns.\")\n",
    "if ID_COL not in test_df.columns:\n",
    "    raise ValueError(\"test.csv must contain 'id' column.\")\n",
    "\n",
    "cat_onehot = [c for c in cat_onehot if c in train_df.columns]\n",
    "cat_freq = [c for c in cat_freq if c in train_df.columns]\n",
    "numeric_features = [c for c in numeric_cols_all if c in train_df.columns and c not in (ID_COL, TARGET)]\n",
    "\n",
    "print(f\"Numeric features ({len(numeric_features)}): {numeric_features}\")\n",
    "print(f\"One-hot categorical ({len(cat_onehot)}): {cat_onehot}\")\n",
    "print(f\"Freq categorical ({len(cat_freq)}): {cat_freq}\")\n",
    "\n",
    "if 'Penalty' in train_df.columns:\n",
    "    train_df['Penalty'] = train_df['Penalty'].fillna('NoPenalty')\n",
    "if 'Penalty' in test_df.columns:\n",
    "    test_df['Penalty'] = test_df['Penalty'].fillna('NoPenalty')\n",
    "\n",
    "def build_preprocessor(onehot_cols, freq_cols, numeric_cols, use_sparse_ohe=USE_SPARSE_OHE):\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    onehot_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Missing\")),\n",
    "        (\"ohe\", make_ohe(sparse_output=use_sparse_ohe))\n",
    "    ])\n",
    "    freq_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Missing\")),\n",
    "        (\"freq\", FrequencyEncoder(normalize=True))\n",
    "    ])\n",
    "\n",
    "    transformers = []\n",
    "    if len(onehot_cols) > 0:\n",
    "        transformers.append((\"onehot\", onehot_transformer, onehot_cols))\n",
    "    if len(freq_cols) > 0:\n",
    "        transformers.append((\"freq\", freq_transformer, freq_cols))\n",
    "    if len(numeric_cols) > 0:\n",
    "        transformers.append((\"num\", numeric_transformer, numeric_cols))\n",
    "\n",
    "    pre = ColumnTransformer(transformers=transformers, remainder=\"drop\", verbose_feature_names_out=False)\n",
    "    return pre\n",
    "\n",
    "\n",
    "def get_feature_names(column_transformer):\n",
    "    out_names = []\n",
    "    for name, trans, cols in column_transformer.transformers_:\n",
    "        if name == \"remainder\":\n",
    "            continue\n",
    "        if hasattr(trans, \"named_steps\"):\n",
    "            last_step = list(trans.named_steps.items())[-1][1]\n",
    "            if isinstance(last_step, OneHotEncoder):\n",
    "                out_names.extend(last_step.get_feature_names_out(cols).tolist())\n",
    "            elif isinstance(last_step, FrequencyEncoder):\n",
    "                out_names.extend([c + \"_freq\" for c in cols])\n",
    "            else:\n",
    "                out_names.extend(cols)\n",
    "        else:\n",
    "            out_names.extend(cols)\n",
    "    return out_names\n",
    "\n",
    "\n",
    "X_full = train_df.drop(columns=[TARGET])\n",
    "y_full = train_df[TARGET].values\n",
    "\n",
    "\n",
    "models = [\n",
    "    (\"xgb\", XGBRegressor(**xgb_params)),\n",
    "    (\"rf\", RandomForestRegressor(**rf_params)),\n",
    "    (\"et\", ExtraTreesRegressor(**et_params))\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "for model_name, model_obj in models:\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"Running model: {model_name}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    test_preds_cv = np.zeros(len(test_df), dtype=float)\n",
    "    oof_preds = np.zeros(len(train_df), dtype=float)\n",
    "    fold_rmse = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_full, y_full), 1):\n",
    "        print(f\"\\n-- Fold {fold}/{n_splits} --\")\n",
    "        X_tr = X_full.iloc[train_idx].reset_index(drop=True)\n",
    "        y_tr = y_full[train_idx]\n",
    "        X_va = X_full.iloc[val_idx].reset_index(drop=True)\n",
    "        y_va = y_full[val_idx]\n",
    "\n",
    "        pre = build_preprocessor(cat_onehot, cat_freq, numeric_features, use_sparse_ohe=USE_SPARSE_OHE)\n",
    "        pre.fit(X_tr)\n",
    "\n",
    "        X_tr_t = pre.transform(X_tr)\n",
    "        X_va_t = pre.transform(X_va)\n",
    "        X_test_t = pre.transform(test_df)\n",
    "\n",
    "        feat_names = get_feature_names(pre)\n",
    "        X_tr_df = pd.DataFrame(X_tr_t, columns=feat_names, index=X_tr.index)\n",
    "        X_va_df = pd.DataFrame(X_va_t, columns=feat_names, index=X_va.index)\n",
    "        X_test_df = pd.DataFrame(X_test_t, columns=feat_names, index=test_df.index)\n",
    "\n",
    "        if model_name == \"xgb\":\n",
    "            model = XGBRegressor(**xgb_params)\n",
    "        elif model_name == \"rf\":\n",
    "            model = RandomForestRegressor(**rf_params)\n",
    "        else:\n",
    "            model = ExtraTreesRegressor(**et_params)\n",
    "\n",
    "        model.fit(X_tr_df, y_tr)\n",
    "\n",
    "        pred_val = model.predict(X_va_df)\n",
    "        oof_preds[val_idx] = pred_val\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(y_va, pred_val))\n",
    "        fold_rmse.append(rmse)\n",
    "        print(f\"Fold {fold} RMSE: {rmse:.4f}\")\n",
    "\n",
    "        test_pred = model.predict(X_test_df)\n",
    "        test_preds_cv += test_pred / n_splits\n",
    "\n",
    "    mean_rmse = np.mean(fold_rmse)\n",
    "    std_rmse = np.std(fold_rmse)\n",
    "    overall_oof = np.sqrt(mean_squared_error(y_full, oof_preds))\n",
    "\n",
    "    print(f\"\\n{model_name.upper()} CV folds RMSE: {['{:.4f}'.format(r) for r in fold_rmse]}\")\n",
    "    print(f\"{model_name.upper()} CV mean RMSE: {mean_rmse:.4f} ± {std_rmse:.4f}\")\n",
    "    print(f\"{model_name.upper()} OOF RMSE: {overall_oof:.4f}\")\n",
    "\n",
    "    print(f\"\\nTraining final {model_name} on full training data...\")\n",
    "    pre_full = build_preprocessor(cat_onehot, cat_freq, numeric_features, use_sparse_ohe=USE_SPARSE_OHE)\n",
    "    pre_full.fit(X_full)\n",
    "\n",
    "    X_full_t = pre_full.transform(X_full)\n",
    "    X_test_t = pre_full.transform(test_df)\n",
    "\n",
    "    feat_names_full = get_feature_names(pre_full)\n",
    "    X_full_df = pd.DataFrame(X_full_t, columns=feat_names_full, index=X_full.index)\n",
    "    X_test_df = pd.DataFrame(X_test_t, columns=feat_names_full, index=test_df.index)\n",
    "\n",
    "    if model_name == \"xgb\":\n",
    "        final_model = XGBRegressor(**xgb_params)\n",
    "    elif model_name == \"rf\":\n",
    "        final_model = RandomForestRegressor(**rf_params)\n",
    "    else:\n",
    "        final_model = ExtraTreesRegressor(**et_params)\n",
    "\n",
    "    final_model.fit(X_full_df, y_full)\n",
    "\n",
    "    joblib.dump(final_model, f\"{model_name}_final_model.joblib\")\n",
    "    joblib.dump(pre_full, f\"{model_name}_preprocessor.joblib\")\n",
    "    print(f\"Saved {model_name}_final_model.joblib and {model_name}_preprocessor.joblib\")\n",
    "\n",
    "    test_pred_final = final_model.predict(X_test_df)\n",
    "\n",
    "    out_cv_avg = pd.DataFrame({ID_COL: test_df[ID_COL].values, TARGET: test_preds_cv})\n",
    "    out_cv_avg.to_csv(f\"output_cv_avg_{model_name}.csv\", index=False)\n",
    "\n",
    "    out_final = pd.DataFrame({ID_COL: test_df[ID_COL].values, TARGET: test_pred_final})\n",
    "    out_final.to_csv(f\"output_{model_name}.csv\", index=False)\n",
    "\n",
    "    print(f\"Wrote output_cv_avg_{model_name}.csv and output_{model_name}.csv\")\n",
    "    print(f\"Finished model: {model_name}\\n\")\n",
    "\n",
    "print(\"All done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd2c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "##3 best\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "train_path = r\"C:\\Users\\chara\\OneDrive\\Desktop\\gdgc\\dataset\\train.csv\"\n",
    "test_path  = r\"C:\\Users\\chara\\OneDrive\\Desktop\\gdgc\\dataset\\test.csv\"\n",
    "\n",
    "\n",
    "def make_ohe(sparse_output=False):\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=sparse_output)\n",
    "    except TypeError:\n",
    "       \n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse=not sparse_output)\n",
    "\n",
    "\n",
    "\n",
    "class FrequencyEncoder(BaseEstimator, TransformerMixin):\n",
    "    def _init_(self, normalize=True):\n",
    "        self.normalize = normalize\n",
    "        self.freq_maps_ = {}\n",
    "        self.columns_ = None\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        cols = input_features if input_features is not None else self.columns_\n",
    "        return [str(c) + \"_freq\" for c in cols]\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_df = pd.DataFrame(X)\n",
    "        self.columns_ = [str(c) for c in X_df.columns.tolist()]\n",
    "        for idx, orig_col in enumerate(X_df.columns):\n",
    "            col_str = self.columns_[idx]\n",
    "            vc = X_df[orig_col].value_counts(normalize=self.normalize, dropna=False)\n",
    "            self.freq_maps_[col_str] = vc.to_dict()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_df = pd.DataFrame(X, columns=self.columns_)\n",
    "        out = pd.DataFrame(index=X_df.index)\n",
    "        for col in self.columns_:\n",
    "            mapping = self.freq_maps_.get(col, {})\n",
    "            out[col + \"_freq\"] = X_df[col].map(mapping).fillna(0.0).astype(float)\n",
    "        return out.values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cat_onehot = ['Formula_category_x', 'Formula_Track_Condition',\n",
    "              'Tire_Compound', 'Penalty', 'Session', 'weather', 'track']\n",
    "cat_freq = ['Formula_shortname', 'circuit_name']\n",
    "\n",
    "\n",
    "numeric_cols_all = ['id', 'Unique ID', 'Rider_ID', 'Len_Circuit_inkm', 'Laps',\n",
    "                    'Start_Position', 'Formula_Avg_Speed_kmh', 'Humidity_%',\n",
    "                    'Champ_Points', 'Champ_Position', 'race_year', 'seq', 'position',\n",
    "                    'points', 'Corners_in_Lap', 'Tire_Degradation_Factor_per_Lap',\n",
    "                    'Pit_Stop_Duration_Seconds', 'Ambient_Temperature_Celsius',\n",
    "                    'Track_Temperature_Celsius', 'air', 'ground', 'starts',\n",
    "                    'finishes', 'with_points', 'podiums', 'wins', 'Lap_Time_Seconds']\n",
    "\n",
    "n_splits = 8 \n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "rf_params  = dict(n_estimators=220, max_depth=None, random_state=42, n_jobs=-1)\n",
    "\n",
    "USE_SPARSE_OHE = False\n",
    "\n",
    "ID_COL = \"id\"\n",
    "TARGET = \"Lap_Time_Seconds\"\n",
    "print(\"Loading train/test CSVs...\")\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df  = pd.read_csv(test_path)\n",
    "\n",
    "\n",
    "if ID_COL not in train_df.columns or TARGET not in train_df.columns:\n",
    "    raise ValueError(\"train.csv must contain 'id' and 'Lap_Time_Seconds' columns.\")\n",
    "if ID_COL not in test_df.columns:\n",
    "    raise ValueError(\"test.csv must contain 'id' column.\")\n",
    "\n",
    "cat_onehot = [c for c in cat_onehot if c in train_df.columns]\n",
    "cat_freq = [c for c in cat_freq if c in train_df.columns]\n",
    "numeric_features = [c for c in numeric_cols_all if c in train_df.columns and c not in (ID_COL, TARGET)]\n",
    "\n",
    "print(f\"Numeric features ({len(numeric_features)}): {numeric_features}\")\n",
    "print(f\"One-hot categorical ({len(cat_onehot)}): {cat_onehot}\")\n",
    "print(f\"Freq categorical ({len(cat_freq)}): {cat_freq}\")\n",
    "\n",
    "\n",
    "if 'Penalty' in train_df.columns:\n",
    "    train_df['Penalty'] = train_df['Penalty'].fillna('NoPenalty')\n",
    "if 'Penalty' in test_df.columns:\n",
    "    test_df['Penalty'] = test_df['Penalty'].fillna('NoPenalty')\n",
    "\n",
    "\n",
    "X_full = train_df.drop(columns=[TARGET])\n",
    "y_full = train_df[TARGET].values\n",
    "\n",
    "\n",
    "def build_preprocessor(onehot_cols, freq_cols, numeric_cols, use_sparse_ohe=USE_SPARSE_OHE):\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    onehot_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Missing\")),\n",
    "        (\"ohe\", make_ohe(sparse_output=use_sparse_ohe))\n",
    "    ])\n",
    "    freq_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Missing\")),\n",
    "        (\"freq\", FrequencyEncoder(normalize=True))\n",
    "    ])\n",
    "\n",
    "    transformers = []\n",
    "    if len(onehot_cols) > 0:\n",
    "        transformers.append((\"onehot\", onehot_transformer, onehot_cols))\n",
    "    if len(freq_cols) > 0:\n",
    "        transformers.append((\"freq\", freq_transformer, freq_cols))\n",
    "    if len(numeric_cols) > 0:\n",
    "        transformers.append((\"num\", numeric_transformer, numeric_cols))\n",
    "\n",
    "    pre = ColumnTransformer(transformers=transformers, remainder=\"drop\", verbose_feature_names_out=False)\n",
    "    return pre\n",
    "\n",
    "def get_feature_names(column_transformer):\n",
    "    out_names = []\n",
    "    for name, trans, cols in column_transformer.transformers_:\n",
    "        if name == \"remainder\":\n",
    "            continue\n",
    "        if hasattr(trans, \"named_steps\"):\n",
    "            last_step = list(trans.named_steps.items())[-1][1]\n",
    "            if isinstance(last_step, OneHotEncoder):\n",
    "                out_names.extend(last_step.get_feature_names_out(cols).tolist())\n",
    "            elif isinstance(last_step, FrequencyEncoder):\n",
    "                out_names.extend([c + \"_freq\" for c in cols])\n",
    "            else:\n",
    "                out_names.extend(cols)\n",
    "        else:\n",
    "            out_names.extend(cols)\n",
    "    return out_names\n",
    "\n",
    "\n",
    "models = [\n",
    "    (\"rf\", RandomForestRegressor(**rf_params))\n",
    "]\n",
    "\n",
    "for model_name, model_obj in models:\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"Running model: {model_name}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    \n",
    "    test_preds_cv = np.zeros(len(test_df), dtype=float)\n",
    "    oof_preds = np.zeros(len(train_df), dtype=float)\n",
    "    fold_rmse = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_full, y_full), 1):\n",
    "        print(f\"\\n-- Fold {fold}/{n_splits} --\")\n",
    "        X_tr = X_full.iloc[train_idx].reset_index(drop=True)\n",
    "        y_tr = y_full[train_idx]\n",
    "        X_va = X_full.iloc[val_idx].reset_index(drop=True)\n",
    "        y_va = y_full[val_idx]\n",
    "\n",
    "\n",
    "        pre = build_preprocessor(cat_onehot, cat_freq, numeric_features, use_sparse_ohe=USE_SPARSE_OHE)\n",
    "        pre.fit(X_tr)\n",
    "\n",
    "        X_tr_t = pre.transform(X_tr)\n",
    "        X_va_t = pre.transform(X_va)\n",
    "        X_test_t = pre.transform(test_df)\n",
    "\n",
    "        feat_names = get_feature_names(pre)\n",
    "\n",
    "       \n",
    "        X_tr_df = pd.DataFrame(X_tr_t, columns=feat_names, index=X_tr.index)\n",
    "        X_va_df = pd.DataFrame(X_va_t, columns=feat_names, index=X_va.index)\n",
    "        X_test_df = pd.DataFrame(X_test_t, columns=feat_names, index=test_df.index)\n",
    "\n",
    "     \n",
    "        if model_name == \"xgb\":\n",
    "            model = XGBRegressor(**xgb_params)\n",
    "        else:\n",
    "            model = RandomForestRegressor(**rf_params)\n",
    "\n",
    "        model.fit(X_tr_df, y_tr)\n",
    "\n",
    "        pred_val = model.predict(X_va_df)\n",
    "        oof_preds[val_idx] = pred_val\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(y_va, pred_val))\n",
    "        fold_rmse.append(rmse)\n",
    "        print(f\"Fold {fold} RMSE: {rmse:.4f}\")\n",
    "\n",
    "       \n",
    "        test_pred = model.predict(X_test_df)\n",
    "        test_preds_cv += test_pred / n_splits\n",
    "\n",
    "    mean_rmse = np.mean(fold_rmse)\n",
    "    std_rmse = np.std(fold_rmse)\n",
    "    overall_oof = np.sqrt(mean_squared_error(y_full, oof_preds))\n",
    "\n",
    "    print(f\"\\n{model_name.upper()} CV folds RMSE: {['{:.4f}'.format(r) for r in fold_rmse]}\")\n",
    "    print(f\"{model_name.upper()} CV mean RMSE: {mean_rmse:.4f} ± {std_rmse:.4f}\")\n",
    "    print(f\"{model_name.upper()} OOF RMSE: {overall_oof:.4f}\")\n",
    "\n",
    "    \n",
    "    print(f\"\\nTraining final {model_name} on full training data...\")\n",
    "    pre_full = build_preprocessor(cat_onehot, cat_freq, numeric_features, use_sparse_ohe=USE_SPARSE_OHE)\n",
    "    pre_full.fit(X_full)\n",
    "\n",
    "    X_full_t = pre_full.transform(X_full)\n",
    "    X_test_t  = pre_full.transform(test_df)\n",
    "\n",
    "    feat_names_full = get_feature_names(pre_full)\n",
    "    X_full_df = pd.DataFrame(X_full_t, columns=feat_names_full, index=X_full.index)\n",
    "    X_test_df = pd.DataFrame(X_test_t, columns=feat_names_full, index=test_df.index)\n",
    "\n",
    "    if model_name == \"xgb\":\n",
    "        final_model = XGBRegressor(**xgb_params)\n",
    "    else:\n",
    "        final_model = RandomForestRegressor(**rf_params)\n",
    "\n",
    "    final_model.fit(X_full_df, y_full)\n",
    "\n",
    "    \n",
    "    joblib.dump(final_model, f\"{model_name}_final_model.joblib\")\n",
    "    joblib.dump(pre_full, f\"{model_name}_preprocessor.joblib\")\n",
    "    print(f\"Saved {model_name}_final_model.joblib and {model_name}_preprocessor.joblib\")\n",
    "\n",
    "    \n",
    "    test_pred_final = final_model.predict(X_test_df)\n",
    "\n",
    "    \n",
    "    out_cv_avg = pd.DataFrame({ID_COL: test_df[ID_COL].values, TARGET: test_preds_cv})\n",
    "    out_cv_avg.to_csv(f\"output_cv_avg_{model_name}.csv\", index=False)\n",
    "\n",
    "    out_final = pd.DataFrame({ID_COL: test_df[ID_COL].values, TARGET: test_pred_final})\n",
    "    out_final.to_csv(f\"output_{model_name}.csv\", index=False)\n",
    "\n",
    "    print(f\"Wrote output_cv_avg_{model_name}.csv and output_{model_name}.csv\")\n",
    "    print(f\"Finished model: {model_name}\\n\")\n",
    "\n",
    "print(\"All done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affc6c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67da134e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
